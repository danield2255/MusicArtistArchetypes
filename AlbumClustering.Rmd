---
title: "Understanding Archetypes of Musical Albums with PCA and K-Means Clustering"
author: "Daniel DeFoe"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE)
```

```{r, include=FALSE}
library(tidyverse)
library(ggridges)
library(ggplot2)
library(viridis)
library(RColorBrewer)
library(dplyr) 
library(mltools)
library(rlang)
library(reshape2)
library(stringi)
library(flipPlots)
library(kableExtra)
library(formattable)
set.seed(41)
```
<style>
  thead {
     font-size: 9.5px;
  }
</style>

## Intro
Computational grouping through clustering could provide an interesting perspective to us about what music is similar and dissimilar. Human understanding of artistic likeness in music is often confined to labels such as genre, but how do we arrive at genre definition? The landscape of musical art is so vast and constantly evolving that it can be difficult to effectively compare and contrast large groups of content. There are so many variables which make up music that it would be hard for a human to consider them all effectively and appropriately. Clustering algorithms provide a reduced bias alternative method of grouping content, where the input considerations can be controlled. This is extremely useful because if what is important is considering the comparison of the music itself, then controlling the input to only be the artistic musical elements will limits the algorithm's view and base its groups only on these artistic elements. The limiting of input will ensure that the algorithm is not affected by the outside influencing factors that humans use as part of their method of grouping content. After groups are created, we can investigate what factors caused them to end up the way the did, and we can reconsider the data that we hid from the algorithm before the data was clustered. 

This project will carry out clustering of music at the level of albums, with data of individual songs being aggregated by album. After all the aggregation 4,125 albums were considered. More detailed music data would likely produce more sophisticated groupings, but the data used to cluster was Spotify's API data of songs aggregated to the album level. Principle component analysis will first be carried out to consider combinations of variables which are most useful in separating the data, as this will hopefully reduce the effect of noise in the data. Then the top principle components which give together explain the greatest proportion of variance in the data will be clustered using K-means clustering. By clustering the principle components instead of the raw data we hope to have to better separated clusters than if we cluster the raw data points, thus better definitions for what these groups mean. 

## Data Subset Creations
One dataset is made to include only the average of all the subjective spotify measures and then another is made to include more expressions(maximums and ranges) of some of these measures. 
```{r, include=FALSE}
df = read_csv("Data/attrsOfAlbsFinal.csv")
df = within(df,  id <- paste(Album, Artist, sep="---"))


#data with all elements artist has control over when making album
dfAll = df %>%
  select(id, numSongsOnAlb, totalDurationSeconds, avgTempo, rangeTempo, moreCommonMajMin, presenceUncommonTS, totalExplicit, proportionExplicit, avgAcousticness, maxAcousticnessTrack, avgDanceability, maxDanceabilityTrack, rangeEnergy, avgEnergy, maxInstrumentalnessTrack, avgInstrumentalness, avgLiveness, maxLivenessTrack, avgLoudness, rangeLoudness, avgSpeechiness, maxSpeechinessTrack, avgValence, rangeValence)


#subset that is really just the objective data
dfObjectiveOnly = df %>%
  select(id, ReleaseYear, Genres, Gender, Group.Solo, RiaaStatus, Label, numGrammys, NumAlbums, YearFirstAlbum, popularGenres)

```



The genre of the album will be inferred by grabbing the larger, more general common genre names from the list of all the songs genres in the album. First the top 10 genres from all of the albums will be determined. Ultimately each album will be categorized with these 10 genres when applicable. We will try to establish a primary, secondary, and tertiary genre where applicable. 
```{r, include = FALSE}
dfObjectiveOnly["Genres"] = lapply(dfObjectiveOnly["Genres"], gsub, pattern = "hip hop", replacement = "hip-hop", fixed = TRUE) 


mostCommonGenres = dfObjectiveOnly["Genres"] %>%
  tolower() %>%
  str_split("(,|\\s|\")") %>%
  unlist() %>%
  table() %>%
  sort(decreasing = TRUE)

##Takes the top 10 genres
mostCommonGenres = mostCommonGenres[-1] %>%
  head(10) %>%
  names()


topGenreFinder = function(genres){
  if (is.na(genres)){
    topGenres = c("Other")
    return (topGenres)
  }
  commonGenrePresence = str_count(genres, mostCommonGenres)
  top3 = order(commonGenrePresence, decreasing = TRUE)[1:3]
  for (i in top3){
    if (commonGenrePresence[i] == 0){
      top3 = top3[top3 != i]
    }
  }
  if (is_empty(top3)){
    topGenres = c("Other")
  } else{
    topGenres = mostCommonGenres[top3]    
  }
  return (topGenres)
}


Genres = lapply(1:nrow(dfObjectiveOnly), function(rNum) { topGenreFinder(dfObjectiveOnly[rNum, "Genres"])})

genreDf = data.frame(t(sapply(Genres, `length<-`, 3)))
names(genreDf) = c("Genre1", "Genre2", "Genre3")

dfObjectiveOnly= cbind(dfObjectiveOnly,genreDf)
dfObjectiveOnly = dfObjectiveOnly %>% select(-Genres)
```




There is also data for each year on what the estimated most three most popular genres of the year were. For each album it will be determined if the album's primary genre (Genre1) was one of these three most popular. 
```{r, include=FALSE}
dfObjectiveOnly$Genre1InYearTop = ifelse(stri_detect_fixed(dfObjectiveOnly$popularGenres, dfObjectiveOnly$Genre1), TRUE, FALSE)
```
Also, because there is data on the release year of the album and the year of the artist's first album release, it can be worthwhile to consider how long an artist has been active on each current release by calculating the years since the first album. 
```{r, include=FALSE}
dfObjectiveOnly$YearsSinceFirst = dfObjectiveOnly$ReleaseYear - dfObjectiveOnly$YearFirstAlbum
```





## Section 1: Principle Component Roadmap
Principle component analysis (PCA) is a form of dimension reduction that takes extracts features from the whole set of input variables to measure how associated each variable is to one another and the relative importance of each of these variables and all of their combinations. The product of PCA is a matrix of loading values for each principle component. All of the principle components together account for 100% of the variance in the data, but the purpose of PCA usually is to take as few principle components as possible to explain the most variance as possible. This means we will ultimately be trying to maximize this trade-off of number of principle components versus proportion of the data's variance explained. The dataset with the complete set of Spotify measures was plugged into PCA and the proportion of the variance captured in each principle component is seen in the barplot. 
```{r, include=FALSE}
pcaOfData = function(df){
  ids = df[,1]
  dfSub = df[,-1]
  pca = prcomp(dfSub, center = TRUE, scale. = TRUE)
  propExplained = pca$sdev^2/sum(pca$sdev^2)
  barplot(propExplained, xlab = "Principle Component", ylab = "Proportion Variance Explained", main="Variance Explained By Each PC",ylim = c(0, 0.3),xlim = c(0, 11), names.arg = seq(1:24))
  pca$x = cbind(ids, data.frame(pca$x))
  return (pca)
}

```

```{r}
pcsSpotifyAndObjectives = pcaOfData(dfAll)
```

It looks like the first 2 principle components are explaining almost 40% of the variance and then the there is a significant decrease in the proportion explained by PC 2 and PC 3 and the next slightly less significant decrease is from PC 5 to PC 6. After the 5th principle component, such little variance is being explained by each following principlce component that there would likely be more hinderence than value from them if they were considered in the analysis. For this reason, for the purposes of this investigation, subsets within the first 5 principle components will be considered. The different  The rotation of the principle components shows the vector loadings for the collection of features and a quick analysis of this will be done to attempt to loosely define each of the first 5 principle components. 


```{r}
pcsSpotifyAndObjectives$rotation[,1:5]
```


Here we will define that the PC's can generally be considered as follows:
- PC1: Measure of how explicit an album is compiled with how dancable and speechy it is. 
- PC2: Measure of how low energy, low volume, high dynamic, and acoustic an album is.
- PC3: How short an album is, and how its very likely not live with also measuring how acoustic, dancable, and low energy it is.
- PC4: Measure of how long, instrumental, happy, and dancable an album is that is not live
- PC5: Measure of how short, explicit, instrumental, slow, and sad an album is.



## Section 2: Clustering and Observation of Metadata Distributions
Now that the data has gone through PCA and we have chosen the optimal number of potentially useful principle components and given them each loose definitions, now the data will go through unsupervised K-means clustering. As previously stated, we are clustering the principle components to hopefully reduce the effect of noise in the data from grouping the data effectively based on the most distincitive characteristic factors. For each subset of principle components which we plug into K-means, the within group sum of squared error will be calculated and plotted against the number of clusters to see the optimal number of groups for the particular input.



```{r, include=FALSE}
kMeansPipeline = function(df, numClusts){
  dataSub = as.data.frame(df)
  dataSub = dataSub[,-1]
  wss <- (nrow(dataSub)-1)*sum(apply(dataSub,2,var))
  for (i in 2:50) wss[i] <- sum(kmeans(dataSub,centers=i)$withinss)
  plot(1:50, wss, type="b", xlab="Number of Clusters",
       ylab="Within groups sum of squares")
  
  k <- kmeans(dataSub, numClusts,iter.max=1000)
  clustDf = as.data.frame(df)
  clustDf$cluster = as.factor(k$cluster)
  return(clustDf)
}
```




```{r, include=FALSE}
artistClusterCount = function(clusterData){
  artistCounts = clusterData %>%
    separate(id, c("Album", "Artist"), "---") %>%
    select(Artist, cluster) %>%
    group_by(cluster, Artist) %>%
    summarise(countInClusts = n())
  return(artistCounts)
}
```


```{r, include=FALSE}
###Function to rejoin two datasets
reattachData = function(clustData, objectiveData){
  newData = clustData %>%
    inner_join(objectiveData, by = "id") %>%
    distinct()
  return(newData)
}

## Groupby to count
countInClusters = function(df, cols){
  counts = df %>%
    group_by(cluster, !!!syms(cols))%>%
    summarise(countInClusts = n()) %>%
    unite(Group, cols)
  return(counts)
}


## chains previous functions to make stacked bar charts showing the proportions of each group for each cluster
stackedBarByClust = function(df, vals) {
  reattachData = reattachData(df, dfObjectiveOnly)
  countOfReattached = countInClusters(reattachData, vals)
  valProportionsReattached = countOfReattached %>%
    group_by(cluster) %>%
    mutate(proportion = countInClusts/sum(countInClusts))
  
  ggplot(valProportionsReattached, aes(x = cluster, y =proportion, fill = Group), na.rm =TRUE) +
    geom_bar(position = "fill",stat = 'identity', na.rm = TRUE) +
    labs(x = "Cluster", y = "Proportion", title = paste("Distribution of ",  paste(vals, collapse = " and ") ," In Each Cluster", sep = ""))
}


## a function to join back the objective data for each album and then see the distribution of a numeric value across clusters in a ridge density plot
numericDistributionEachClust = function(df, val){
  reattached = reattachData(df, dfObjectiveOnly)
  
  ggplot(reattached, aes_string(x = val, y ="cluster", fill = "..x.."), na.rm =TRUE) +
    geom_density_ridges_gradient(scale = .75, rel_min_height = 0.01) +
    scale_fill_viridis(option = "C") +
    labs(title = paste('Distribution of Album ', val, " Across Clusters")) +
    theme(legend.position="none")
}

## optional modification to the "numericDistributionEachClust" function if wanting it to be expressed as a histogrma ridge plot
numericDistributionEachClust2 = function(df, val){
  reattached = reattachData(df, dfObjectiveOnly)
  
  ggplot(reattached, aes_string(x = val, y ="cluster"), na.rm =TRUE) +
    geom_density_ridges(alpha = 0.6, stat="binline", bins=20) +
    scale_fill_viridis(option = "C") +
    labs(title = paste('Distribution of Album ', val, " Across Clusters")) +
    theme(legend.position="none")
}

coloredTableDisplay = function(df){
  reattachedProcessed = reattachData(df, dfAll) %>%
    select(c("cluster","avgDanceability", "avgEnergy", "avgAcousticness", "avgSpeechiness", "avgInstrumentalness", "proportionExplicit", "avgLiveness", "avgValence", "totalDurationSeconds", "avgTempo", "moreCommonMajMin", "proportionExplicit", "avgLoudness", "avgSpeechiness")) %>%
    mutate_at(vars(c("avgDanceability", "avgEnergy", "avgAcousticness", "avgSpeechiness", "avgInstrumentalness", "proportionExplicit", "avgLiveness", "avgValence", "totalDurationSeconds", "avgTempo", "moreCommonMajMin", "proportionExplicit", "avgLoudness", "avgSpeechiness")), funs(scale)) %>%
    group_by(cluster) %>%
    summarise_all(mean) %>%
    mutate_at(-1, funs(round(., 3)))

  
  
  kTable = formattable(reattachedProcessed, align = "l", list(formatter("span", style = style("font-size:5px;")),
  `cluster` = formatter("span", style = ~ style(color = "grey",font.weight = "bold","border-radius" = "0px")), 
                     area(col = -1) ~ function(x) percent(x / 100, digits = 0),
                     area(col = -1) ~ function(x)ifelse(x<=0, color_tile("red", "transparent")(x*c(x<=0)), 
                                    color_tile("transparent", "forest green")(x*c(x>=0))))) 
  

  return(kTable)
}
  

```







```{r}
#Function to show an average metric in each cluster
avgMetricsinClusts = function(dfInput, vals){
  reattached = reattachData(dfInput, df)
  processedData = reattached %>%
    select(cluster, vals) %>% 
    mutate_at(vars(vals), funs(scale)) %>%####Values standardized before groupby and mean
    group_by(cluster) %>%
    summarise_at(vars(vals), mean) %>%
    gather(key= "Attribute", value = "Value", vals)
  
  
  ggplot(processedData, aes(x = cluster, y =Value, fill = Attribute), na.rm =TRUE) +
    geom_bar(stat="identity",position = "dodge", na.rm = TRUE) +
    labs(x = "Cluster", y = "Average Value", title = paste("Average  ",  paste(vals, collapse = " and ") ," in Each Cluster", sep = ""))
}

```




The first 5 principle components will be available to cluster, but changing the number of top PC's we cluster on should hopefully not change the general meaning of the clusters too much. Different combinations of the first N principle components and different values of K will be tested to see what factors are defining the clusters most prominantly. The greatest decrease in variance explained by far is after the 2nd principle component, and the next notable decrease is between the 5th and 6th principle. For these reasons, the first 5 principle components could have potential to be the most useful; therefore, various clustering combinations using the first 5 principle components will be compared. Given a constant number of clusters K, we should expect a reasonably similar pattern in the traits of each cluster still. 

First the clustering will be done using only the 1st and 2nd principle components. The curve of the withing group sum of square error slightly suggests that the best number of clusters is 4, so that will be used. 
```{r}
first2Pcs4Clusts = kMeansPipeline(data.frame(pcsSpotifyAndObjectives$x[,1:3]), 4)
```

```{r, include=FALSE}
## just some artist presence counters
artistCount=artistClusterCount(first2Pcs4Clusts)
johnMayerAppearances = artistCount %>%
  filter(Artist == "John Mayer")
print(johnMayerAppearances)

maroon5Appearances = artistCount %>%
  filter(Artist == "Maroon 5")
print(maroon5Appearances)
```



```{r}
avgMetricsinClusts(first2Pcs4Clusts,  c("avgDanceability", "avgEnergy", "avgAcousticness", "avgSpeechiness", "avgInstrumentalness", "proportionExplicit", "avgLiveness", "avgValence", "totalDurationSeconds", "avgTempo", "moreCommonMajMin", "proportionExplicit", "avgLoudness", "avgSpeechiness"))
coloredTableDisplay(first2Pcs4Clusts)


```

This first attempt at clustering seems to form visible groups with some defining characteristics such as one cluster having high acousticness and low energy and dancability and another having high relative speechiness and propotion of explicit songs. The cluster with high speehiness and high proportion of explicit songs was also overwhelmingly represented by albums that had the primary genre of rap. This evidence may suggest that this first model would do a good job at seperately grouping rap albums and acoustic albums correctly. 


Now the first 3 principle components will be what is clustered on. The within groups sum of squares plot now shows that if may be useful to use 5 clusters. We will try using both 4 and 5 clusters to compare. The first will use 4 clusters. 
```{r}
first3Pcs4Clusts = kMeansPipeline(data.frame(pcsSpotifyAndObjectives$x[,1:4]), 4)
```

```{r}
avgMetricsinClusts(first3Pcs4Clusts,  c("avgDanceability", "avgEnergy", "avgAcousticness", "avgSpeechiness", "avgInstrumentalness", "proportionExplicit", "avgLiveness", "avgValence", "totalDurationSeconds", "avgTempo", "moreCommonMajMin", "proportionExplicit", "avgLoudness", "avgSpeechiness"))
```



It seems that the addition of the third PC helps define another cluster (here cluster 2) as long, instrumental full, live albums. This is a good sign because PC 3 had a significant load for liveness. This is a good addition to the model because we are looking for features of clusters which are different from one another to see separation between them. 



Now the same 3 principle components with 5 clusters. 
```{r, include=FALSE}
first3Pcs5Clusts = kMeansPipeline(data.frame(pcsSpotifyAndObjectives$x[,1:4]), 5)
```


```{r}
avgMetricsinClusts(first3Pcs5Clusts,  c("avgDanceability", "avgEnergy", "avgAcousticness", "avgSpeechiness", "avgInstrumentalness", "proportionExplicit", "avgLiveness", "avgValence", "totalDurationSeconds", "avgTempo", "moreCommonMajMin", "proportionExplicit", "avgLoudness", "avgSpeechiness"))
```



The addition of a 5th cluster does not show predominant traits right away, and it can be that this "added cluster" is cluster 4, with all of its levels pretty close to 0. However, the genre distribution plot shows there may be better separation of genres.

Now the first 5 principle components will be clustered on. First only 4 clusters will be used. The number of clusters will be increased until 7 since the within group sum of squares plot seems to decrease steepest until the 7th cluster. 
```{r}
first5Pcs4Clusts = kMeansPipeline(data.frame(pcsSpotifyAndObjectives$x[,1:6]), 4)
```

```{r}
avgMetricsinClusts(first5Pcs4Clusts,  c("avgDanceability", "avgEnergy", "avgAcousticness", "avgSpeechiness", "avgInstrumentalness", "proportionExplicit", "avgLiveness", "avgValence", "totalDurationSeconds", "avgTempo", "moreCommonMajMin", "proportionExplicit", "avgLoudness", "avgSpeechiness"))
```




Here it seems that the first 5 PC's give virtually the same results as the first 3. This is a good result for the sake of reliability of 4 clusters doing a good job at separating the data. 



Next will be 5 clusters.
```{r, include=FALSE}
first5Pcs5Clusts = kMeansPipeline(data.frame(pcsSpotifyAndObjectives$x[,1:6]), 5)
```

```{r}
avgMetricsinClusts(first5Pcs5Clusts,  c("avgDanceability", "avgEnergy", "avgAcousticness", "avgSpeechiness", "avgInstrumentalness", "proportionExplicit", "avgLiveness", "avgValence", "totalDurationSeconds", "avgTempo", "moreCommonMajMin", "proportionExplicit", "avgLoudness", "avgSpeechiness"))
```




With the first 5 PC's included in making 5 clusters, the liveness cluster which was previously was created when we added the 3rd principle component gets split and allows the groups to be a bit more nuanced, as now there are 2 clusters which are high in liveness. We now see of these 2 that the cluster higher in liveness has a relatively low average acousticness, and the other had relatively low danceability and was relatively long in duration. (option)(An explanation for this could be that the one low in dancability is full of solos that may lessen the dancability of the songs) 



Now with 6 clusters.
```{r, include=FALSE}
first5Pcs6Clusts = kMeansPipeline(data.frame(pcsSpotifyAndObjectives$x[,1:6]), 6)
```

```{r}
avgMetricsinClusts(first5Pcs6Clusts,  c("avgDanceability", "avgEnergy", "avgAcousticness", "avgSpeechiness", "avgInstrumentalness", "proportionExplicit", "avgLiveness", "avgValence", "totalDurationSeconds", "avgTempo", "moreCommonMajMin", "proportionExplicit", "avgLoudness", "avgSpeechiness"))
```



It seems that when 6 clusters are initialized that there are 2 clusters with virtually the same characteristics being relatively high in danceability, speechiness, and explicitness. Both of these clusters were mostly solo male rap albums. This additional cluster does not accomplish much as it seems like it is separating albums which actually do have similar traits to one another. We cannot see the difference in the data by which this separation is being made, so it does not provide much information. 


Finally, with 7 clusters. 
```{r, include=FALSE}
first5Pcs7Clusts = kMeansPipeline(data.frame(pcsSpotifyAndObjectives$x[,1:6]), 7)
```






```{r}
avgMetricsinClusts(first5Pcs7Clusts,  c("avgDanceability", "avgEnergy", "avgAcousticness", "avgSpeechiness", "avgInstrumentalness", "proportionExplicit", "avgLiveness", "avgValence", "totalDurationSeconds", "avgTempo", "moreCommonMajMin", "proportionExplicit", "avgLoudness", "avgSpeechiness"))
```




This appears to give similar results to 6 clusters, where the rap cluster is split without much information as to why, and then that a new cluster without definitive features is added.


With an extensive search through the different combinations the model which will be chosen to be further observed is the model using the first 5 principle components and 5 clusters. 


```{r}
#Now that the combination of PC's and clusters we want to analyze has been chosen, rejoin all data
dfReattached = reattachData(reattachData(first5Pcs5Clusts, dfObjectiveOnly), dfAll)
```



Use analysis of variance (ANOVA) to test numerical difference of means between multiple groups, which are the clusters. 
```{r}
#Tuckey's Pairwise??
#Do this for all/more?
dfReattachedSpotify = reattachData(first5Pcs5Clusts, dfAll)
summary(aov(numGrammys ~ cluster, data = dfReattached))
TukeyHSD(aov(numGrammys ~ cluster, data = dfReattached))
summary(aov(ReleaseYear ~ cluster, data = dfReattached))
TukeyHSD(aov(ReleaseYear ~ cluster, data = dfReattached))

```




## Section 3: Specific Questions About Clusters
We have determined the model that used the first 5 PC's to form 5 clusters was the best, so now we can try to speculate about the groups which were formed. The following visualizations show what the properties are of albums making up each cluster. 




```{r}
avgMetricsinClusts(first5Pcs5Clusts,  c("avgDanceability", "avgEnergy", "avgAcousticness", "avgSpeechiness", "avgInstrumentalness", "proportionExplicit", "avgLiveness", "avgValence", "totalDurationSeconds", "avgTempo", "moreCommonMajMin", "proportionExplicit", "avgLoudness", "avgSpeechiness"))
avgMetricsinClusts(first5Pcs5Clusts, c("avgEnergy", "avgAcousticness"))
avgMetricsinClusts(first5Pcs5Clusts, c("avgSpeechiness", "proportionExplicit"))
avgMetricsinClusts(first5Pcs5Clusts, c("numGrammys", "presenceUncommonTS"))
avgMetricsinClusts(first5Pcs5Clusts, c("numSongsOnAlb", "totalExplicit", "NumAlbums"))
avgMetricsinClusts(first5Pcs5Clusts, c("avgLoudness", "rangeLoudness"))
```



```{r}
stackedBarByClust(first5Pcs5Clusts, c("Gender"))
stackedBarByClust(first5Pcs5Clusts, c("Group.Solo"))
stackedBarByClust(first5Pcs5Clusts, c("Genre1"))
stackedBarByClust(first5Pcs5Clusts, c("Gender", "Group.Solo"))

```


```{r}
numericDistributionEachClust(first5Pcs5Clusts, 'ReleaseYear')

numericDistributionEachClust(first5Pcs5Clusts, 'YearsSinceFirst')
```
### Question 1: What are the rock albums in the 'rap cluster', and why are they there?
With cluster 3 so strongly being represented by primarily rap albums and so lowly being represented by rock albums, it may be worth asking what rock albums are being put into this group if the clustering algorithm seems to be able to separate them so well? What about these rock albums is causing them to be put here?

```{r}
reattachData(first5Pcs5Clusts, dfObjectiveOnly) %>%
  filter(cluster == 3 & Genre1 == "rock")
```
The answer to this is reasonably simple. The rock albums which are being put in cluster 3 are filled with narration tracks. Two rock albums were placed in cluster3 and one was just completely an interview and the other had a discussion track between each song. All of this music-less conversation strongly boosts the average speechiness of the album. This high speechiness score is expressed in the combination of PC loadings and ultimately encourages the albums to be clustered with other albums with high amounts of speeciness, and most of these are rap albums. 


### Question 2: What is characteristic of the cluster with the highest proportion of female artists? What genres are being covered by these female artists in this cluster high in acousticness?
Males dominated the billboard charts between 1999 and 2019, and each cluster's proportion of men far outweighed that of women. However, the cluster with the greatest proportion of female representation was cluster 4, which was the group with high acousticness and low engery. These descriptors could apply to various genere labels however, so some further investigation may be done to see which genres that females are playing in this "soft music" cluster. First a chi-squared test of independence can be done to see if there is a statistically significant difference in the average proportion of each gender's representation accross the clusters.
```{r}
chisq.test(dfReattached$cluster, dfReattached$Gender)

dfReattached %>%
  group_by(cluster, Gender) %>%
  summarise(n = n()) %>%
  mutate(freq = n / sum(n))
```
With a p-value less than 2.2 * e^-16 there is strong evidence to conclude that the average proportions of each gender are not equal in all clusters. This is apparent in the table where we see ___________. 

The following graphic shows the distribution of primary genres of albums by female artists across the clusters. 

```{r}
reattachedDataF = reattachData(first5Pcs5Clusts, dfObjectiveOnly) %>%
  filter(Gender == "F")
countOfReattached = countInClusters(reattachedDataF, c("Genre1"))
valProportionsReattached = countOfReattached %>%
  group_by(cluster) %>%
  mutate(proportion = countInClusts/sum(countInClusts))
  
ggplot(valProportionsReattached, aes(x = cluster, y =proportion, fill = Group), na.rm =TRUE) +
  geom_bar(position = "fill",stat = 'identity', na.rm = TRUE) +
  labs(x = "Cluster", y = "Proportion", title = paste("Distribution of ",  "Primary Album Genre" ," In Each Cluster for Female Artists", sep = ""))

head(reattachedDataF)

```
It seems that in the cluster made up of the greatest proportion of female artists that pop was the most prevalent genre, but this is true for all the female populations each cluster. 



```{r}
## every column put into sankey diagram is a layer
femaleGenres = reattachedDataF %>%
  select(Genre1, Genre2, Genre3) %>%
  group_by(Genre1, Genre2, Genre3) %>%
  summarise(count = n())
print(femaleGenres)
SankeyDiagram(femaleGenres[, c(-3, -4)],
              link.color = "Source", 
              weights = femaleGenres$count) 
```


Observing count of albums of each female artist who was in cluster 4 may help provide some insight as well. 

```{r}
artistClusterCount(reattachedDataF)  %>%
  filter(cluster == 4) %>%
  arrange(desc(countInClusts))
```
It seems that the female artists with the most representation in this cluster all play different genres of softer music, and this makes sense because they are in the cluster high in acousticness.

So while a single genre label might not exist to express it, there may be evidence to suggest that popular female artists tend to have more commonly played soft music. This may even suggest there is a type of music more associated with female artists. IS THIS CORRECT TO SAY BECAUSE IT DOES NOT SOUND LIKE IT. 


### Question 3: What are the genres being covered by all of these male groups in the cluster with the far greater group density?

Here, cluster 2 will be focused on because it has the greatest proportion of groups, mostly represented by male groups. We already established a significant difference in the proportions of gender in each cluster, and we can again use a chi-squared test of independence to test for a difference in the proportion of group and solo artist albums across clusters. 

```{r}
chisq.test(dfReattached$cluster, dfReattached$Group.Solo)
dfReattached %>%
  group_by(cluster, Group.Solo) %>%
  summarise(n = n()) %>%
  mutate(freq = n / sum(n))
```
Again, with a p-value less than 2.2 * e^-16 there is strong evidence to conclude that the average proportions of group and solo artist albums are not equal in all clusters.

```{r}
reattachedDataClust2 = reattachData(first5Pcs5Clusts, dfObjectiveOnly) %>%
  filter(cluster == 2, Group.Solo == "Group")
countInClusters(reattachedDataClust2, c("Genre1")) %>%
  arrange(desc(countInClusts))

```

The primary genre of albums by groups in this cluster is rock, followed not too far behind by pop.

## Takeaways 
This investigation of grouping albums by purely musical characteristics 

## Apendix

Thes are all output gathered from testing various PC and K cluster combinations. 

```{r}
plot(pcsSpotifyAndObjectives$x[, c(2,3)], col=first2Pcs4Clusts$cluster, pch=16)
stackedBarByClust(first5Pcs4Clusts, c("Gender"))
stackedBarByClust(first5Pcs4Clusts, c("Group.Solo"))
stackedBarByClust(first5Pcs4Clusts, c("Genre1"))
numericDistributionEachClust(first2Pcs4Clusts, 'ReleaseYear')
numericDistributionEachClust(first2Pcs4Clusts, 'YearsSinceFirst')
```


```{r}
plot(pcsSpotifyAndObjectives$x[, c(2,3)], col=first3Pcs4Clusts$cluster, pch=16)
plot(pcsSpotifyAndObjectives$x[, c(2,4)], col=first3Pcs4Clusts$cluster, pch=16)
plot(pcsSpotifyAndObjectives$x[, c(3,4)], col=first3Pcs4Clusts$cluster, pch=16)
stackedBarByClust(first3Pcs4Clusts, c("Gender"))
stackedBarByClust(first3Pcs4Clusts, c("Group.Solo"))
stackedBarByClust(first3Pcs4Clusts, c("Genre1"))
numericDistributionEachClust(first3Pcs4Clusts, 'ReleaseYear')
numericDistributionEachClust(first3Pcs4Clusts, 'YearsSinceFirst')
```


```{r}
plot(pcsSpotifyAndObjectives$x[, c(2,3)], col=first3Pcs5Clusts$cluster, pch=16)
plot(pcsSpotifyAndObjectives$x[, c(2,4)], col=first3Pcs5Clusts$cluster, pch=16)
plot(pcsSpotifyAndObjectives$x[, c(3,4)], col=first3Pcs5Clusts$cluster, pch=16)
stackedBarByClust(first3Pcs5Clusts, c("Gender"))
stackedBarByClust(first3Pcs5Clusts, c("Group.Solo"))
stackedBarByClust(first3Pcs5Clusts, c("Genre1"))
numericDistributionEachClust(first3Pcs5Clusts, 'ReleaseYear')
numericDistributionEachClust(first3Pcs5Clusts, 'YearsSinceFirst')
```


```{r}
plot(pcsSpotifyAndObjectives$x[, c(2,3)], col=first5Pcs4Clusts$cluster, pch=16)
plot(pcsSpotifyAndObjectives$x[, c(2,4)], col=first5Pcs4Clusts$cluster, pch=16)
plot(pcsSpotifyAndObjectives$x[, c(2,5)], col=first5Pcs4Clusts$cluster, pch=16)
plot(pcsSpotifyAndObjectives$x[, c(2,6)], col=first5Pcs4Clusts$cluster, pch=16)
plot(pcsSpotifyAndObjectives$x[, c(3,4)], col=first5Pcs4Clusts$cluster, pch=16)
plot(pcsSpotifyAndObjectives$x[, c(3,5)], col=first5Pcs4Clusts$cluster, pch=16)
plot(pcsSpotifyAndObjectives$x[, c(3,6)], col=first5Pcs4Clusts$cluster, pch=16)
plot(pcsSpotifyAndObjectives$x[, c(4,5)], col=first5Pcs4Clusts$cluster, pch=16)
plot(pcsSpotifyAndObjectives$x[, c(4,6)], col=first5Pcs4Clusts$cluster, pch=16)
plot(pcsSpotifyAndObjectives$x[, c(5,6)], col=first5Pcs4Clusts$cluster, pch=16)
stackedBarByClust(first5Pcs4Clusts, c("Gender"))
stackedBarByClust(first5Pcs4Clusts, c("Group.Solo"))
stackedBarByClust(first5Pcs4Clusts, c("Genre1"))
numericDistributionEachClust(first5Pcs4Clusts, 'ReleaseYear')
numericDistributionEachClust(first5Pcs4Clusts, 'YearsSinceFirst')
```


```{r}
plot(pcsSpotifyAndObjectives$x[, c(2,3)], col=first5Pcs5Clusts$cluster, pch=16)
plot(pcsSpotifyAndObjectives$x[, c(2,4)], col=first5Pcs5Clusts$cluster, pch=16)
plot(pcsSpotifyAndObjectives$x[, c(2,5)], col=first5Pcs5Clusts$cluster, pch=16)
plot(pcsSpotifyAndObjectives$x[, c(2,6)], col=first5Pcs5Clusts$cluster, pch=16)
plot(pcsSpotifyAndObjectives$x[, c(3,4)], col=first5Pcs5Clusts$cluster, pch=16)
plot(pcsSpotifyAndObjectives$x[, c(3,5)], col=first5Pcs5Clusts$cluster, pch=16)
plot(pcsSpotifyAndObjectives$x[, c(3,6)], col=first5Pcs5Clusts$cluster, pch=16)
plot(pcsSpotifyAndObjectives$x[, c(4,5)], col=first5Pcs5Clusts$cluster, pch=16)
plot(pcsSpotifyAndObjectives$x[, c(4,6)], col=first5Pcs5Clusts$cluster, pch=16)
plot(pcsSpotifyAndObjectives$x[, c(5,6)], col=first5Pcs5Clusts$cluster, pch=16)
stackedBarByClust(first5Pcs5Clusts, c("Gender"))
stackedBarByClust(first5Pcs5Clusts, c("Group.Solo"))
stackedBarByClust(first5Pcs5Clusts, c("Genre1"))
numericDistributionEachClust(first5Pcs5Clusts, 'ReleaseYear')
numericDistributionEachClust(first5Pcs5Clusts, 'YearsSinceFirst')
```


```{r}
plot(pcsSpotifyAndObjectives$x[, c(2,3)], col=first5Pcs6Clusts$cluster, pch=16)
plot(pcsSpotifyAndObjectives$x[, c(2,4)], col=first5Pcs6Clusts$cluster, pch=16)
plot(pcsSpotifyAndObjectives$x[, c(2,5)], col=first5Pcs6Clusts$cluster, pch=16)
plot(pcsSpotifyAndObjectives$x[, c(2,6)], col=first5Pcs6Clusts$cluster, pch=16)
plot(pcsSpotifyAndObjectives$x[, c(3,4)], col=first5Pcs6Clusts$cluster, pch=16)
plot(pcsSpotifyAndObjectives$x[, c(3,5)], col=first5Pcs6Clusts$cluster, pch=16)
plot(pcsSpotifyAndObjectives$x[, c(3,6)], col=first5Pcs6Clusts$cluster, pch=16)
plot(pcsSpotifyAndObjectives$x[, c(4,5)], col=first5Pcs6Clusts$cluster, pch=16)
plot(pcsSpotifyAndObjectives$x[, c(4,6)], col=first5Pcs6Clusts$cluster, pch=16)
plot(pcsSpotifyAndObjectives$x[, c(5,6)], col=first5Pcs6Clusts$cluster, pch=16)
stackedBarByClust(first5Pcs6Clusts, c("Gender"))
stackedBarByClust(first5Pcs6Clusts, c("Group.Solo"))
stackedBarByClust(first5Pcs6Clusts, c("Genre1"))
numericDistributionEachClust(first5Pcs6Clusts, 'ReleaseYear')
numericDistributionEachClust(first5Pcs6Clusts, 'YearsSinceFirst')
```



```{r}
plot(pcsSpotifyAndObjectives$x[, c(2,3)], col=first5Pcs7Clusts$cluster, pch=16)
plot(pcsSpotifyAndObjectives$x[, c(2,4)], col=first5Pcs7Clusts$cluster, pch=16)
plot(pcsSpotifyAndObjectives$x[, c(2,5)], col=first5Pcs7Clusts$cluster, pch=16)
plot(pcsSpotifyAndObjectives$x[, c(2,6)], col=first5Pcs7Clusts$cluster, pch=16)
plot(pcsSpotifyAndObjectives$x[, c(3,4)], col=first5Pcs7Clusts$cluster, pch=16)
plot(pcsSpotifyAndObjectives$x[, c(3,5)], col=first5Pcs7Clusts$cluster, pch=16)
plot(pcsSpotifyAndObjectives$x[, c(3,6)], col=first5Pcs7Clusts$cluster, pch=16)
plot(pcsSpotifyAndObjectives$x[, c(4,5)], col=first5Pcs7Clusts$cluster, pch=16)
plot(pcsSpotifyAndObjectives$x[, c(4,6)], col=first5Pcs7Clusts$cluster, pch=16)
plot(pcsSpotifyAndObjectives$x[, c(5,6)], col=first5Pcs7Clusts$cluster, pch=16)
stackedBarByClust(first5Pcs7Clusts, c("Gender"))
stackedBarByClust(first5Pcs7Clusts, c("Group.Solo"))
stackedBarByClust(first5Pcs7Clusts, c("Genre1"))
numericDistributionEachClust(first5Pcs7Clusts, 'ReleaseYear')
numericDistributionEachClust(first5Pcs7Clusts, 'YearsSinceFirst')
```





















